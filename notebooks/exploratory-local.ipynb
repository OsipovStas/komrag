{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "S9sDzRUdB8LS",
   "metadata": {
    "executionInfo": {
     "elapsed": 56218,
     "status": "ok",
     "timestamp": 1729362455343,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "S9sDzRUdB8LS"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -q pyngrok dagshub mlflow python-dotenv langchain langchain-openai langchain-together langchain-community pypdf pinecone streamlit langchain-pinecone langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee7cbb4",
   "metadata": {
    "executionInfo": {
     "elapsed": 362,
     "status": "ok",
     "timestamp": 1729362459838,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "cee7cbb4"
   },
   "outputs": [],
   "source": [
    "#@markdown **You need to sign up for [DagsHub](https://dagshub.com/user/sign_up) , then enter the name of the repository you'd like to create, and your username and email.**\n",
    "\n",
    "#@markdown Enter the repository name for the project:\n",
    "REPO_NAME= \"komrag\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Enter the username of your DAGsHub account:\n",
    "USER_NAME = \"OsipovStas\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown Enter the email for your DAGsHub account:\n",
    "EMAIL = \"stasstels@gmail.com\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d55e39fc",
   "metadata": {
    "id": "d55e39fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../app/.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vHvqIRLyCW_w",
   "metadata": {
    "executionInfo": {
     "elapsed": 4180,
     "status": "ok",
     "timestamp": 1729362506776,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "vHvqIRLyCW_w"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "DH_TOKEN = userdata.get('LLM_MATH_COMP_DH_TOKEN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1ba4d",
   "metadata": {
    "id": "1be1ba4d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DH_TOKEN = os.environ['LLM_MATH_COMP_DH_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4771e432",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 65
    },
    "executionInfo": {
     "elapsed": 3276,
     "status": "ok",
     "timestamp": 1729362511776,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "4771e432",
    "outputId": "d6dfd76a-6a97-40a7-c375-6e27c74a31b6"
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import dagshub\n",
    "import os\n",
    "#DH_TOKEN = os.environ['LLM_MATH_COMP_DH_TOKEN']\n",
    "username = f'{USER_NAME}'  # Replace with your DagsHub username\n",
    "repository = f'{REPO_NAME}'  # Replace with your repository name\n",
    "token = f'{DH_TOKEN}'  # Replace with your DagsHub token\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = username\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = token\n",
    "dagshub.auth.add_app_token(token)\n",
    "dagshub.init(repo_name=REPO_NAME, repo_owner=USER_NAME)\n",
    "mlflow.set_tracking_uri(f\"https://dagshub.com/{USER_NAME}/{REPO_NAME}.mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OoRLzACECgbM",
   "metadata": {
    "executionInfo": {
     "elapsed": 4457,
     "status": "ok",
     "timestamp": 1729362535085,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "OoRLzACECgbM"
   },
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_API_KEY'] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = \"true\"\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = \"https://api.smith.langchain.com\"\n",
    "os.environ['LANGCHAIN_PROJECT'] = \"komrag\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dVY_HUuGClyB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "executionInfo": {
     "elapsed": 2279,
     "status": "ok",
     "timestamp": 1729362572299,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "dVY_HUuGClyB",
    "outputId": "0cd01138-9ac1-4730-af67-eedab15ec792"
   },
   "outputs": [],
   "source": [
    "from dagshub import get_repo_bucket_client\n",
    "# Get a boto3.client object\n",
    "s3 = get_repo_bucket_client(\"OsipovStas/komrag\")\n",
    "\n",
    "# Upload file\n",
    "s3.upload_file(\n",
    "    Bucket=\"komrag\",  # name of the repo\n",
    "    Filename=\"./life_begin.pdf\",  # local path of file to upload\n",
    "    Key=\"life_begin.pdf\",  # remote path where to upload the file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec09123",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "executionInfo": {
     "elapsed": 1936,
     "status": "ok",
     "timestamp": 1729362567047,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "1ec09123",
    "outputId": "06ab2591-e9a8-400a-ce93-298d41196ffd"
   },
   "outputs": [],
   "source": [
    "from dagshub import get_repo_bucket_client\n",
    "# Get a boto3.client object\n",
    "s3 = get_repo_bucket_client(\"OsipovStas/komrag\")\n",
    "\n",
    "\n",
    "s3.download_file(\n",
    "    Bucket=\"komrag\",  # name of the repo\n",
    "    Key=\"life_begin.pdf\",  #  remote path from where to download the file\n",
    "    Filename=\"life_begin.pdf\",  # local path where to download the file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tuESoPn5Ecbw",
   "metadata": {
    "id": "tuESoPn5Ecbw"
   },
   "outputs": [],
   "source": [
    "from dagshub.notebook import save_notebook\n",
    "\n",
    "save_notebook(repo=f\"{USER_NAME}/{REPO_NAME}\", path=\"./notebooks/exploratory-local.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SxU-q2FnC8L5",
   "metadata": {
    "id": "SxU-q2FnC8L5"
   },
   "source": [
    "# LLM Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f468bd",
   "metadata": {
    "id": "e7f468bd"
   },
   "outputs": [],
   "source": [
    "model=\"gpt-4o-mini-2024-07-18\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25036f3c",
   "metadata": {
    "id": "25036f3c"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "chat = AzureChatOpenAI(model=model, temperature=0, timeout=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Se1Y40hrDAuu",
   "metadata": {
    "executionInfo": {
     "elapsed": 5427,
     "status": "ok",
     "timestamp": 1729362670175,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "Se1Y40hrDAuu"
   },
   "outputs": [],
   "source": [
    "from langchain_together import ChatTogether\n",
    "\n",
    "# choose from our 50+ models here: https://docs.together.ai/docs/inference-models\n",
    "chat = ChatTogether(\n",
    "    together_api_key=userdata.get(\"TOGETHER_KEY\"),\n",
    "    model=\"meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo\",\n",
    "    timeout=120\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b10fe05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 661,
     "status": "ok",
     "timestamp": 1729362672456,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "6b10fe05",
    "outputId": "d5923794-50f1-48d4-a5b6-e9dc8f0e4111"
   },
   "outputs": [],
   "source": [
    "chat.invoke(\"Hello, do you know russian? Write a response in it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb9e663",
   "metadata": {
    "id": "bfb9e663"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(model=\"text-embedding-3-small-1\", dimensions=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vzqW0JyhDHNf",
   "metadata": {
    "executionInfo": {
     "elapsed": 1682,
     "status": "ok",
     "timestamp": 1729362691708,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "vzqW0JyhDHNf"
   },
   "outputs": [],
   "source": [
    "from langchain_together import TogetherEmbeddings\n",
    "\n",
    "embeddings = TogetherEmbeddings(\n",
    "    together_api_key=userdata.get(\"TOGETHER_KEY\"),\n",
    "    model=\"togethercomputer/m2-bert-80M-8k-retrieval\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c33949",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 671,
     "status": "ok",
     "timestamp": 1729362698715,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "b7c33949",
    "outputId": "66f67901-7959-444f-ce3a-165d639bf2c9"
   },
   "outputs": [],
   "source": [
    "len(embeddings.embed_query(\"Приветы, как дела?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FwAzQy45Czxp",
   "metadata": {
    "id": "FwAzQy45Czxp"
   },
   "source": [
    "# Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c93bc0",
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1729362707713,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "19c93bc0"
   },
   "outputs": [],
   "source": [
    "file_path = \"life_begin.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dc715e",
   "metadata": {
    "executionInfo": {
     "elapsed": 19175,
     "status": "ok",
     "timestamp": 1729362730845,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "37dc715e"
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(file_path)\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57547153",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1729362749817,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "57547153",
    "outputId": "67d07ab4-1d49-4aac-f4e6-e73b196b57db"
   },
   "outputs": [],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9MRcohVaDRxV",
   "metadata": {
    "id": "9MRcohVaDRxV"
   },
   "source": [
    "# Text cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04775fd4",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1729362752163,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "04775fd4"
   },
   "outputs": [],
   "source": [
    "template=\"\"\"\n",
    "You will receive a text in Russian extracted using an OCR tool.\n",
    "Your task is to clean and format this text to enhance readability.\n",
    "The text may contain various artifacts introduced during the OCR process, such as:\n",
    "\n",
    " - Special characters or symbols that do not belong.\n",
    " - Inconsistent casing of letters (e.g., random uppercase or lowercase letters).\n",
    " - Incorrect spacing within words or between words (e.g., words glued together or unnecessary spaces).\n",
    " - Hyphenation errors, such as words split across lines.\n",
    " - Incorrect punctuation or misplaced commas and periods.\n",
    " - New line characters\n",
    "\n",
    "Please ensure the final output is free from these artifacts and is well-formatted.\n",
    "Pay attention to punctuation, paragraph structure, and overall coherence.\n",
    "The goal is to produce a clean, easy-to-read text.\n",
    "Output ONLY the cleaned text.\n",
    "\n",
    "\n",
    "### TEXT ###\n",
    "\n",
    "{text}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bee8be",
   "metadata": {
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1729362755309,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "31bee8be"
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa793c0e",
   "metadata": {
    "executionInfo": {
     "elapsed": 441,
     "status": "ok",
     "timestamp": 1729362756730,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "fa793c0e"
   },
   "outputs": [],
   "source": [
    "chain = prompt | chat | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7051164",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3985,
     "status": "ok",
     "timestamp": 1729362761746,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "f7051164",
    "outputId": "e7a54bee-d794-4063-81c0-4b09db478c0d"
   },
   "outputs": [],
   "source": [
    "print(chain.invoke({\"text\": pages[30].page_content}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee18968",
   "metadata": {
    "id": "7ee18968"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # try up to 3 times if no success return text as is\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            return (chain.invoke({\"text\": text}), True)\n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning text: {e}\")\n",
    "    return (text, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b56db50",
   "metadata": {
    "id": "7b56db50"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "failures = []\n",
    "for p in tqdm(pages, desc=\"Cleaning text\", unit=\"page\"):\n",
    "  text, suc = clean_text(p.page_content)\n",
    "  if not suc:\n",
    "    failures.append(p)\n",
    "  else:\n",
    "    p.page_content = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e02440",
   "metadata": {
    "id": "83e02440"
   },
   "outputs": [],
   "source": [
    "print(pages[3].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e5l1W0Di3d",
   "metadata": {
    "id": "10e5l1W0Di3d"
   },
   "source": [
    "# Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c2faf",
   "metadata": {
    "id": "7d4c2faf"
   },
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "splits = text_splitter.split_documents(pages)\n",
    "\n",
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0201fe",
   "metadata": {
    "id": "fa0201fe"
   },
   "outputs": [],
   "source": [
    "splits[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2vTMIQfYDl8T",
   "metadata": {
    "id": "2vTMIQfYDl8T"
   },
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d710dfce",
   "metadata": {
    "id": "d710dfce"
   },
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=os.environ['PINECONE_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc53c1",
   "metadata": {
    "executionInfo": {
     "elapsed": 1527,
     "status": "ok",
     "timestamp": 1729362893108,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "0edc53c1"
   },
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "\n",
    "pc = pinecone.Pinecone(api_key=userdata.get('PINECONE_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8555fe4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1729362896543,
     "user": {
      "displayName": "",
      "userId": ""
     },
     "user_tz": -180
    },
    "id": "8555fe4c",
    "outputId": "a7a2cb65-793f-43c9-9f17-d1f679635ba6"
   },
   "outputs": [],
   "source": [
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddff0d32",
   "metadata": {
    "id": "ddff0d32"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = \"komrag\"  # change if desired\n",
    "\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=768,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "        time.sleep(1)\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46865d7",
   "metadata": {
    "id": "d46865d7"
   },
   "outputs": [],
   "source": [
    "pc.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b8effa",
   "metadata": {
    "id": "d4b8effa"
   },
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f053d5fe",
   "metadata": {
    "id": "f053d5fe"
   },
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def generate_id(content):\n",
    "    # Ensure the content is in bytes\n",
    "    if isinstance(content, str):\n",
    "        content = content.encode('utf-8')\n",
    "\n",
    "    # Create a SHA-256 hash object\n",
    "    hash_object = hashlib.sha256()\n",
    "\n",
    "    # Update the hash object with the content\n",
    "    hash_object.update(content)\n",
    "\n",
    "    # Get the hexadecimal representation of the hash\n",
    "    unique_id = hash_object.hexdigest()\n",
    "\n",
    "    return unique_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67901e8",
   "metadata": {
    "id": "e67901e8"
   },
   "outputs": [],
   "source": [
    "def index_all_docs(docs):\n",
    "  # process docs by batches of 100 docs using tqdm\n",
    "  for i in tqdm(range(0, len(docs), 100), desc=\"Indexing\", unit=\"batch\"):\n",
    "    index_batch(docs[i:i+100])\n",
    "\n",
    "def index_batch(docs):\n",
    "  ids = [generate_id(doc.page_content) for doc in docs]\n",
    "  vector_store.add_documents(documents=docs, ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e0e989",
   "metadata": {
    "id": "c8e0e989"
   },
   "outputs": [],
   "source": [
    "index_all_docs(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ade1d3e-bc36-41a0-9f28-6a985f650f92",
   "metadata": {},
   "source": [
    "# Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348adc07-c041-467c-879d-d5a54c99d03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "vectorstore = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59a8d10-6b49-483a-81e6-9f9d72ca4d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"В какой температуре купать ребенка?\")\n",
    "\n",
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5812da8f-9915-407c-83f4-32bc0439dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(retrieved_docs[5].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d47f022-8190-47c9-88b1-654bb45b9275",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a079bcc9-7ab3-4a81-b020-543d0db715fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    ").to_messages()\n",
    "\n",
    "example_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c011e79-eb8c-4f63-91f3-517e30ba00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e490fd0-e53e-439b-8ea5-29722cf9a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for chunk in rag_chain.stream(\"При какой температуре купать ребенка?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8731165-6cc8-434d-8fc2-e8da05746984",
   "metadata": {},
   "source": [
    "# NGROK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872dd94a-dd63-4803-aba1-256b0c56f49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t=2024-10-20T14:39:57+0300 lvl=warn msg=\"invalid tunnel configuration\" pg=/api/tunnels id=b7fac91c62981aa6 err=\"yaml: unmarshal errors:\\n  line 1: field port not found in type config.HTTPv2Tunnel\"\n"
     ]
    }
   ],
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "ngrok.set_auth_token(os.environ['NGROK_KEY'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b68a30-f92d-4a62-8981-44b9e006f395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2lKni4tEcD6SS67BDtSziTmLsUo_3yi5Kwrbo1dgiGfn3xAZx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['NGROK_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "400e8640-873f-4b9e-bcc1-0cd29ac4292f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streamlit app is live at NgrokTunnel: \"https://994d-2602-815-0-4-00-b18.ngrok-free.app\" -> \"http://localhost:8501\"\n"
     ]
    }
   ],
   "source": [
    "# Start ngrok tunnel\n",
    "public_url = ngrok.connect(addr='localhost:8501')\n",
    "print(f\"Streamlit app is live at {public_url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb6f75-906f-4e24-9cfb-760be99ad8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
